{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLRfM_m7vWTl",
    "outputId": "58db7340-afdc-4bc6-f526-8e53c791e5fa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Download code\n",
    "if not os.path.exists('detect_isu.py'):\n",
    "  !git clone https://github.com/donglaiw/yolov7\n",
    "\n",
    "if os.path.exists('yolov7'):\n",
    "  %cd yolov7\n",
    "\n",
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ys8MtwegQOjc"
   },
   "source": [
    "# <b>1. Model setup</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utxvpmuibcI7",
    "outputId": "952b5608-3fa9-46b8-c95a-6897117faf74"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "# Download model weight\n",
    "if not os.path.exists('yolov7.pt'):\n",
    "  # Download model weight\n",
    "  !curl -L -o yolov7.pt https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n",
    "\n",
    "# Create the model\n",
    "from detect_isu import ObjectDetector\n",
    "detector = ObjectDetector()\n",
    "detector.set_conf('weights', 'yolov7.pt')\n",
    "detector.setup_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tARL6gWQgO7L"
   },
   "source": [
    "# <b>2. Test on one image</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2uFYdhKmOBq"
   },
   "source": [
    "## Read and display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "aId1iLXtb7KA",
    "outputId": "496ff448-e5f3-4776-e472-74d0129f6e68"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (40,10)\n",
    "\n",
    "# read the image\n",
    "img = cv2.imread('inference/images/vehicle_test.png')\n",
    "\n",
    "# display the image\n",
    "# cv2.imread: BGR -> plt.imshow(rgb)\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrzOGyJ8mTAe"
   },
   "source": [
    "## Run vehicle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXBSkdRvmTHe",
    "outputId": "23767264-2282-4191-8769-0bfd4e6a2973"
   },
   "outputs": [],
   "source": [
    "output_box = detector.detect(img, ['truck', 'bus', 'car'], do_visual=False)\n",
    "print(f\"detect {output_box.shape[0]} objects\")\n",
    "print(\"The output is a Nx6 matrix\")\n",
    "print(\"Each row is one detection: box coordinates, prediction confidence, class_id\")\n",
    "print('--------')\n",
    "print(\"Let's look at the first detection\")\n",
    "print(output_box[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBbTO-JQmTOe"
   },
   "source": [
    "## Plot the detection result on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "h43SqBu3mTVg",
    "outputId": "52216848-b704-44f9-e5ed-43e616ee2a88"
   },
   "outputs": [],
   "source": [
    "output_visual = detector.plot_box(img[:, :, ::-1], output_box)\n",
    "plt.imshow(output_visual)\n",
    "plt.title('Detetion results')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YenVewKipny6"
   },
   "source": [
    "# <b>3. Test on one video</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiCSlu6Kx32P"
   },
   "source": [
    "## Display the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "JS6jJWLux3Vf",
    "outputId": "77a0caf3-89b4-4773-b805-b68f024f5054"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "def show_video(video_path, video_width = 600):   \n",
    "  video_file = open(video_path, \"r+b\").read() \n",
    "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
    "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n",
    " \n",
    "video_source = 'inference/videos/vehicle_test.mp4'\n",
    "show_video(video_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQfKHxz8yDEQ"
   },
   "source": [
    "## Run detection and save result\n",
    "\n",
    "We will run the detector on every frame from the video and save the output into a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RuiR-0Gdprwj",
    "outputId": "7e6166d1-3ad4-466d-bb99-22da4df0ce0a"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "class VideoWriter(object):\n",
    "    def __init__(self, output_file, fps):\n",
    "      self.output_file = output_file\n",
    "      self.output_folder = output_file[:output_file.rfind('.')] + '/'\n",
    "      self.output_template = '%05d.png'\n",
    "      if not os.path.exists(self.output_folder):\n",
    "        os.mkdir(self.output_folder)\n",
    "      self.fps = fps\n",
    "      self.frame_id = 0\n",
    "    \n",
    "    def write(self, img):\n",
    "      cv2.imwrite(self.output_folder + self.output_template%self.frame_id, img)\n",
    "      self.frame_id += 1\n",
    "\n",
    "    def release(self):\n",
    "      # convert the folder of outputs into a mp4 file\n",
    "      os.system(f'ffmpeg -framerate {self.fps} -i {self.output_folder}{self.output_template} -c:v libx264 -pix_fmt yuv420p {self.output_file}')\n",
    "      # remove the temp folder\n",
    "      os.system(f'rm -r {self.output_folder}')\n",
    "\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "output_video_name = 'detection_output.mp4'\n",
    "output_counter = []\n",
    "\n",
    "if os.path.exists(output_video_name):\n",
    "    os.system(f'rm {output_video_name}')\n",
    "\n",
    "output_video = VideoWriter(output_video_name, fps)\n",
    "\n",
    "frame_id = 0\n",
    "ret = True\n",
    "while ret:\n",
    "    ret, frame = cap.read()        \n",
    "    if ret:\n",
    "        if frame_id % 10 == 0:\n",
    "            print(f'process frame {frame_id}')\n",
    "        output_box = detector.detect(frame, ['truck', 'bus', 'car'], do_visual=False, verbose=False)\n",
    "        output_visual = detector.plot_box(frame, output_box)\n",
    "        output_counter.append(output_box.shape[0])\n",
    "        output_video.write(output_visual)\n",
    "        frame_id += 1\n",
    "        ### to save time, only run it for the first 100 frames\n",
    "        if frame_id > 100:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "output_video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMDKsoIA1_yi"
   },
   "source": [
    "## Visualize result\n",
    "\n",
    "Visualize the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "_ILDJ6Ch95qt",
    "outputId": "7896c068-187a-4117-aa08-e035bb9d513a"
   },
   "outputs": [],
   "source": [
    "show_video(output_video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsrlL0TRtl-E"
   },
   "source": [
    "Plot the vehicle count over time. This shows how AI can be used to monitor traffic automatically in real-time!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "edBVDa28to1Z",
    "outputId": "845101a3-3b7d-4f8a-fad1-3c29f40c1148"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.plot(np.arange(len(output_counter))/fps, output_counter)\n",
    "plt.xlabel('Time (sec)', fontsize=18)\n",
    "plt.ylabel('Number of vehicles', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zI5AK9S9I3h"
   },
   "source": [
    "# <b> [Optional 1] Run with different options</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSbTDWcS9b0R"
   },
   "source": [
    "\n",
    "Repeat section 2 above but with modifying several parameters. \n",
    "\n",
    "## Alter the confidence threshold\n",
    "First, we can make the threshold for recognizing objects be more strict or loose. Change the `conf_thres` parameter below to any value between 0 and 1 and observe the result. What can you deduce about this parameter? How would changing this parameter affect our traffic monitor application above? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 620
    },
    "id": "aSHiCRWZSI-j",
    "outputId": "0a4a3bbc-23ba-429a-8f3d-1286cb48fbbe"
   },
   "outputs": [],
   "source": [
    "# read the image\n",
    "img = cv2.imread('inference/images/vehicle_test.png')\n",
    "\n",
    "output_box = detector.detect(img, ['truck', 'bus', 'car'], do_visual=False,  conf_thres = 0.7)\n",
    "print(f\"detect {output_box.shape[0]} objects\")\n",
    "print(\"The output is a Nx6 matrix\")\n",
    "print(\"Each row is one detection: box coordinates, prediction confidence, class_id\")\n",
    "print('--------')\n",
    "print(\"Let's look at the first detection\")\n",
    "print(output_box[0])\n",
    "output_visual = detector.plot_box(img[:, :, ::-1], output_box)\n",
    "plt.imshow(output_visual)\n",
    "plt.title('Detetion results')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWTbSKbWXYAi"
   },
   "source": [
    "\n",
    "## Alter the image with a 90 degree rotation\n",
    "Play with the parameter `np.rot90` below and observe the changes to detection result. What can you deduce about how image orientation affects the accuracy of detection?\n",
    "\n",
    "Do this twice to see what happens if the image is rotated 180 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "m4fxQuqlXbdL",
    "outputId": "2d8958ee-2c62-4435-88af-7145f81fa109"
   },
   "outputs": [],
   "source": [
    "# read the image\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('inference/images/vehicle_test.png')\n",
    "print(img.__class__)\n",
    "img90 = np.rot90(img)\n",
    "\n",
    "output_box = detector.detect(img90, ['truck', 'bus', 'car'], do_visual=False,  conf_thres = 0.1)\n",
    "print(f\"detect {output_box.shape[0]} objects\")\n",
    "print(\"The output is a Nx6 matrix\")\n",
    "print(\"Each row is one detection: box coordinates, prediction confidence, class_id\")\n",
    "print('--------')\n",
    "print(\"Let's look at the first detection\")\n",
    "if len(output_box) > 0:\n",
    "  print(output_box[0])\n",
    "  output_visual = detector.plot_box(img90[:, :, ::-1], output_box)\n",
    "  plt.imshow(output_visual)\n",
    "  plt.title('Detetion results')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "else:\n",
    "  plt.imshow(img90[:, :, ::-1])\n",
    "  plt.title('Input image')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "img180 = np.rot90(img90)\n",
    "\n",
    "output_box = detector.detect(img180, ['truck', 'bus', 'car'], do_visual=False,  conf_thres = 0.1)\n",
    "print(f\"detect {output_box.shape[0]} objects\")\n",
    "print(\"The output is a Nx6 matrix\")\n",
    "print(\"Each row is one detection: box coordinates, prediction confidence, class_id\")\n",
    "print('--------')\n",
    "print(\"Let's look at the first detection\")\n",
    "if len(output_box) > 0:\n",
    "  print(output_box[0])\n",
    "  output_visual = detector.plot_box(img180[:, :, ::-1], output_box)\n",
    "  plt.imshow(output_visual)\n",
    "  plt.title('Detetion results')\n",
    "  plt.axis('off')\n",
    "  plt.show()\n",
    "else:\n",
    "  plt.imshow(img180[:, :, ::-1])\n",
    "  plt.title('Input image')\n",
    "  plt.axis('off')\n",
    "  plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TUyiTHjaYiR"
   },
   "source": [
    "## Different categories of objects\n",
    "\n",
    "The model was trained on 80 categories of objects, not just trucks and cars. For example, it can also be used to recognize cats and dogs. Play with the 3 examples below to see how it can recognize just cats, just dogs, or both. \n",
    "\n",
    "[***Internet connectivity required***]: if you have the url of an image you want, you can also paste it here to see the result. Warning: some websites do not allow you to load the image directly from there but would rather have you save the image first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "yFVUpWyDaaQV",
    "outputId": "20cc1117-7ee3-442c-b903-31332824b23c"
   },
   "outputs": [],
   "source": [
    "import wget\n",
    "# there are also images in inference/images/\n",
    "imageUrl = 'https://static01.nyt.com/images/2019/10/01/science/00SCI-CATS1/merlin_102054072_34962289-a2a4-4c52-9969-4b2719347e76-superJumbo.jpg?quality=75&auto=webp'\n",
    "filename = wget.download(imageUrl)\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "output_box = detector.detect(img, ['cat'], do_visual=False)\n",
    "print(f\"detect {output_box.shape[0]} objects\")\n",
    "print(\"The output is a Nx6 matrix\")\n",
    "print(\"Each row is one detection: box coordinates, prediction confidence, class_id\")\n",
    "print('--------')\n",
    "print(\"Let's look at the first detection\")\n",
    "print(output_box[0])\n",
    "output_visual = detector.plot_box(img[:, :, ::-1], output_box)\n",
    "plt.imshow(output_visual)\n",
    "plt.title('Detetion results')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "id": "CA7bHuDGb2Hs",
    "outputId": "0aa97f5e-acaa-4476-9861-aa53e69a4534"
   },
   "outputs": [],
   "source": [
    "imageUrl = 'https://epwn.org/wp-content/uploads/2021/08/many-many-dogs.jpg'\n",
    "filename = wget.download(imageUrl)\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "output_box = detector.detect(img, ['dog'], do_visual=False)\n",
    "print(f\"detect {output_box.shape[0]} objects\")\n",
    "print(\"The output is a Nx6 matrix\")\n",
    "print(\"Each row is one detection: box coordinates, prediction confidence, class_id\")\n",
    "print('--------')\n",
    "print(\"Let's look at the first detection\")\n",
    "print(output_box[0])\n",
    "output_visual = detector.plot_box(img[:, :, ::-1], output_box)\n",
    "plt.imshow(output_visual)\n",
    "plt.title('Detetion results')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_yhv7HMeja5"
   },
   "source": [
    "Now put both cat and dog detection on the same image. Do you see any misclassification? What could be causing it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pbOyGJKoccZL",
    "outputId": "62176b15-9974-4118-e95d-f79f18004540"
   },
   "outputs": [],
   "source": [
    "imageUrl = 'https://mypetsashes.co.uk/wp-content/uploads/2015/08/Pet-Cremation-UK-650x650.jpg'\n",
    "filename = wget.download(imageUrl)\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "output_box = detector.detect(img, ['cat', 'dog'], do_visual=False)\n",
    "print(f\"detect {output_box.shape[0]} objects\")\n",
    "print(\"The output is a Nx6 matrix\")\n",
    "print(\"Each row is one detection: box coordinates, prediction confidence, class_id\")\n",
    "print('--------')\n",
    "print(\"Let's look at the first detection\")\n",
    "print(output_box[0])\n",
    "\n",
    "plt.imshow(img[:, :, ::-1])\n",
    "plt.title('Input image')\n",
    "plt.axis('off')\n",
    "plt.show()  \n",
    "\n",
    "output_visual = detector.plot_box(img[:, :, ::-1], output_box)\n",
    "plt.imshow(output_visual)\n",
    "plt.title('Detetion results')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGbeC0tle8oU"
   },
   "source": [
    "Play with more images in this directory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-Uocv6Omly3"
   },
   "source": [
    "# <b>[Optional 2] Image processing</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USIGR8bdmpTW"
   },
   "source": [
    "## How are images represented?\n",
    "\n",
    "Images are just a bunch of numbers! Let's download some images and see how a computer represents them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4riga7EFmt0S",
    "outputId": "67be3cb6-9164-486b-f7cd-9198707bcc85"
   },
   "outputs": [],
   "source": [
    "# download two car images (one color, one grayscale)\n",
    "! wget https://bc-cv.github.io/csci3343/public/kitti/kitti.png -O kitti.png\n",
    "! wget https://bc-cv.github.io/csci3343/public/kitti/kitti_gray.png -O kitti_gray.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ST4MSzgemwBk"
   },
   "source": [
    "Here's a grayscale image (only black and white). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "GZMjg9K0myde",
    "outputId": "ae49c70d-a8d6-45c0-8fab-ff2d61dbb4d2"
   },
   "outputs": [],
   "source": [
    "import imageio.v3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read our grayscale image from the downloaded file\n",
    "image_gray = imageio.v3.imread('kitti_gray.png')\n",
    "\n",
    "print('Image shape:', image_gray.shape)\n",
    "print(\"It's a 2D matrix!\\n\", image_gray)\n",
    "\n",
    "# display the image!\n",
    "plt.figure(figsize=(12, 10)) \n",
    "plt.imshow(image_gray, cmap='gray')\n",
    "# add a title\n",
    "plt.title('Grayscale image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off'); \n",
    "# show it \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b67TdIylm1wB"
   },
   "source": [
    "Here's a color image! The representation is a little more complicated. Instead of one number representing each pixel, we have 3 numbers (in a 3D tensor) representing each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QyOJ_ytym2jX",
    "outputId": "899b1264-01b1-4547-9483-b7239f426e49"
   },
   "outputs": [],
   "source": [
    "# read our color image from the downloaded file\n",
    "image = imageio.v3.imread('kitti.png')\n",
    "\n",
    "print('Image shape:', image.shape)\n",
    "print(\"It's a 3D matrix!\\n\", image)\n",
    "\n",
    "# display the image!\n",
    "plt.figure(figsize=(12, 10)) \n",
    "plt.imshow(image)\n",
    "# add a title\n",
    "plt.title('Color image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off'); \n",
    "# show it \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3cSoLWlm3sM"
   },
   "source": [
    "## Transforming images\n",
    "\n",
    "Since images are just a bunch of numbers, we can apply transformations or operations on those numbers to change how an image looks. This is like applying an image filter on your camera photos on your phone!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVVKDbjSm8ZA"
   },
   "source": [
    "### Basic transformations\n",
    "\n",
    "Simple transformations can be done by simply adding a value to each pixel value. This will make the image lighter or darker!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "o7rIITCOm7dX",
    "outputId": "e2fd3a1e-755a-4ed8-9d00-910a6ac850c2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# we add 60 to each image pixel value\n",
    "def lighten_image_operation(img):\n",
    "  return np.clip((img.astype(float)+100),0,255).astype(np.uint8)\n",
    "\n",
    "lighter_image = lighten_image_operation(image)\n",
    "\n",
    "# display the original image and lighter image side by side\n",
    "plt.figure(figsize=(12, 10)) \n",
    "plt.subplot(121)\n",
    "# show original image\n",
    "plt.imshow(image)\n",
    "# add a title\n",
    "plt.title('Original image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "# show lighter image\n",
    "plt.imshow(lighter_image)\n",
    "# add a title\n",
    "plt.title('Lighter image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off')\n",
    "# show it \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m29s-e4PnAFN"
   },
   "source": [
    "We can also multiply image pixel values to make more contrasted images that look more brighter or darker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "Hk7w0yXanBTC",
    "outputId": "91e7d18c-dabf-412a-8cb5-a34433148bf6"
   },
   "outputs": [],
   "source": [
    "def contrast_image_operation(img):\n",
    "  return np.clip(((img.astype(float)-128)*1.5+128),0,255).astype(np.uint8)\n",
    "\n",
    "contrast_image = contrast_image_operation(image)\n",
    "\n",
    "# display the original image and contrast image side by side\n",
    "plt.figure(figsize=(12, 10)) \n",
    "plt.subplot(121)\n",
    "# show original image\n",
    "plt.imshow(image)\n",
    "# add a title\n",
    "plt.title('Original image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "# show contrast image\n",
    "plt.imshow(contrast_image)\n",
    "# add a title\n",
    "plt.title('Contrast image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off')\n",
    "# show it \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHdYtcYvnCnG"
   },
   "source": [
    "### More advanced transformations\n",
    "\n",
    "A <a href=\"https://www.adobe.com/creativecloud/photography/discover/sepia-photography.html\">sepia filter</a> is an old chemical way to make photograph and now a style of image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "39hertq7nExh",
    "outputId": "8dd54a19-1061-4e94-be56-3d20448033ba"
   },
   "outputs": [],
   "source": [
    "def sepia_filter_operation(img):\n",
    "  color_trans = np.array([[0.189, 0.168, 0.131],\\\n",
    "                        [0.769, 0.686, 0.534],\\\n",
    "                        [0.393, 0.349, 0.272]])\n",
    "  # reshape image into Nx3\n",
    "  img_reshape = img.reshape(-1,3)\n",
    "  # convert image range into 0-1\n",
    "  img_reshape = img / 255.0\n",
    "  # Sepia color transform\n",
    "  img_sepia = np.matmul(img_reshape, color_trans)\n",
    "  # convert it back to 0-255\n",
    "  img_sepia = (np.clip(img_sepia*255,0,255)).astype(np.uint8)\n",
    "  # reshape it back\n",
    "  return img_sepia.reshape(img.shape)\n",
    "\n",
    "sepia_image = sepia_filter_operation(image)\n",
    "\n",
    "# display the original image and contrast image side by side\n",
    "plt.figure(figsize=(12, 10)) \n",
    "plt.subplot(121)\n",
    "# show original image\n",
    "plt.imshow(image)\n",
    "# add a title\n",
    "plt.title('Original image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "# show sepia image\n",
    "plt.imshow(sepia_image)\n",
    "# add a title\n",
    "plt.title('Sepia image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off')\n",
    "# show it \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fReODvSnHRJ"
   },
   "source": [
    "A Gaussian filter can be applied to produce the effect of blurring the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "d3WXo8nPmtFF",
    "outputId": "85dfa0e7-c65a-4756-f03e-8fedbf9e6504"
   },
   "outputs": [],
   "source": [
    "kernel_size = 21 # size of blurring filter\n",
    "sigma = 10 # degree of blur (larger values blur more)\n",
    "blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)\n",
    "\n",
    "# display the original image and contrast image side by side\n",
    "plt.figure(figsize=(12, 10)) \n",
    "plt.subplot(121)\n",
    "# show original image\n",
    "plt.imshow(image)\n",
    "# add a title\n",
    "plt.title('Original image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(122)\n",
    "# show sepia image\n",
    "plt.imshow(blurred_image)\n",
    "# add a title\n",
    "plt.title('Blurry image from a driving car')\n",
    "# turn off the plot axis\n",
    "plt.axis('off')\n",
    "# show it \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUAE9edTnLqa"
   },
   "source": [
    "## How well does our model do?\n",
    "\n",
    "With these transformed images, we can test how well our model does in different situations. What do these results tell us about the performance of our AI model under various situations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 905
    },
    "id": "tK_ImYflnMR4",
    "outputId": "08156ddd-abb0-4273-e249-4ac1d42716b8"
   },
   "outputs": [],
   "source": [
    "output_visual = detector.detect(image, ['truck', 'bus', 'car'], do_visual=True,  conf_thres = 0.5)\n",
    "plt.subplot(411)\n",
    "plt.imshow(output_visual)\n",
    "plt.title('Detetion results on the original image', fontsize=18)\n",
    "plt.axis('off')\n",
    "\n",
    "output_visual = detector.detect(lighter_image, ['truck', 'bus', 'car'], do_visual=True,  conf_thres = 0.5)\n",
    "plt.subplot(412)\n",
    "plt.imshow(output_visual)\n",
    "plt.title('Detetion results on the lighter image', fontsize=18)\n",
    "plt.axis('off')\n",
    "\n",
    "output_visual = detector.detect(sepia_image, ['truck', 'bus', 'car'], do_visual=True,  conf_thres = 0.5)\n",
    "plt.subplot(413)\n",
    "plt.imshow(output_visual)\n",
    "plt.title('Detetion results on the sepia image', fontsize=18)\n",
    "plt.axis('off')\n",
    "\n",
    "output_visual = detector.detect(blurred_image, ['truck', 'bus', 'car'], do_visual=True,  conf_thres = 0.5)\n",
    "plt.subplot(414)\n",
    "plt.imshow(output_visual)\n",
    "plt.title('Detetion results on the blurry image', fontsize=18)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
